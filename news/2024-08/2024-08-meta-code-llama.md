## ðŸ“° Meta's Code Llama Advances Code Generation

**Source:**  
**Date:** August 1, 2024  
**URL:** [https://www.spglobal.com/market-intelligence/en/news-insights/research/generative-ai-latest-breakthroughs-and-developments](https://www.spglobal.com/market-intelligence/en/news-insights/research/generative-ai-latest-breakthroughs-and-developments)  
**Summary:** In August 2024, Meta introduced Code Llama, a code-focused variant of its Llama 2 model, capable of generating both code and natural language. Available in multiple sizes and specialized versions like Code Llama â€“ Python, it enhances coding productivity and safety through instruction tuning.

---

### ðŸ”¹ What Happened

Meta unveiled Code Llama, an AI model designed to assist developers by generating and discussing code. This model is built upon the Llama 2 architecture and is available in various sizes and specialized versions, including Code Llama â€“ Python, to cater to different programming needs. ([about.fb.com](https://about.fb.com/news/2023/08/code-llama-ai-for-coding?utm_source=openai))

### ðŸ”¹ Why It Matters

Code Llama aims to streamline the coding process by providing developers with a tool that can generate code snippets, complete code segments, and debug existing code. Its instruction-tuned variants, such as Code Llama â€“ Instruct, are specifically fine-tuned to understand and respond to natural language instructions, enhancing the safety and reliability of AI-generated code. ([about.fb.com](https://about.fb.com/news/2023/08/code-llama-ai-for-coding?utm_source=openai))

### ðŸ”¹ Who's Involved

- **Meta Platforms Inc.:** The company behind the development and release of Code Llama.
- **AI Developers and Researchers:** The primary users and beneficiaries of Code Llama, utilizing it to improve coding efficiency and safety.

### ðŸ”¹ Technical Details

- **Model Architecture:** Code Llama is based on the Llama 2 large language model, further fine-tuned for code generation tasks.
- **Specialized Versions:**
  - **Code Llama â€“ Python:** A variant fine-tuned specifically on Python code to enhance performance in Python-related tasks.
  - **Code Llama â€“ Instruct:** An instruction-tuned version designed to better understand and follow natural language instructions.
- **Training Data:** The models are trained on extensive code datasets, including sequences of up to 16,000 tokens, with the ability to handle inputs up to 100,000 tokens. ([arxiv.org](https://arxiv.org/abs/2308.12950?utm_source=openai))
- **Performance Benchmarks:** Code Llama has demonstrated state-of-the-art performance among open models on several code benchmarks, achieving scores of up to 67% on HumanEval and 65% on MBPP. ([arxiv.org](https://arxiv.org/abs/2308.12950?utm_source=openai))

### ðŸ“Š Benchmark Results

| Benchmark | Score | Dataset/Task    |
|-----------|-------|-----------------|
| HumanEval | 67%   | Code Generation |
| MBPP      | 65%   | Code Generation |

### ðŸ”— References

- [Meta's Code Llama: Open Foundation Models for Code](https://arxiv.org/abs/2308.12950)
- [Introducing Code Llama, an AI Tool for Coding](https://about.fb.com/news/2023/08/code-llama-ai-for-coding)
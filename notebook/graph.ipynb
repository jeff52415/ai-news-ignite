{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from config import Config\n",
    "config = Config.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-31 22:45:42,531 - utils.prompt_loader - INFO - Preloaded prompt: github_agent.j2\n",
      "2025-05-31 22:45:42,535 - utils.prompt_loader - INFO - Preloaded prompt: news_filter.j2\n",
      "2025-05-31 22:45:42,538 - utils.prompt_loader - INFO - Preloaded prompt: news_format.j2\n",
      "2025-05-31 22:45:42,541 - utils.prompt_loader - INFO - Preloaded prompt: search_agent.j2\n",
      "2025-05-31 22:45:42,546 - utils.prompt_loader - INFO - Preloaded prompt: summarise_agent.j2\n",
      "2025-05-31 22:45:42,549 - utils.prompt_loader - INFO - Preloaded prompt: supervisor_agent.j2\n",
      "2025-05-31 22:45:42,553 - utils.prompt_loader - INFO - Preloaded prompt: supervisor_agent_input.j2\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "from typing import Annotated\n",
    "from pydantic import BaseModel, Field\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Send\n",
    "from langfuse.callback import CallbackHandler\n",
    "from agent.agents import AgentFactory\n",
    "from utils import prompt_loader\n",
    "from data_model.news import NewsArticleList, NewsArticle\n",
    "\n",
    "# --- State Definition ---\n",
    "\n",
    "\n",
    "class NewsGraphState(BaseModel):\n",
    "    input_message: str \n",
    "    news: NewsArticleList | None = Field(default=None, description=\"List of news articles\")\n",
    "    article: NewsArticle | None = Field(default=None, description=\"Single news article for processing\")\n",
    "    results: Annotated[list, operator.add] = Field(default_factory=list, description=\"Results accumulator\")\n",
    "    finished: bool = Field(default=False, description=\"Whether the graph has finished\")\n",
    "\n",
    "# --- Callback and Agent Factory ---\n",
    "\n",
    "\n",
    "langfuse_handler = CallbackHandler()\n",
    "agent_factory = AgentFactory()\n",
    "\n",
    "# --- Node Definitions ---\n",
    "\n",
    "\n",
    "async def search_news(state: NewsGraphState):\n",
    "    \"\"\"Fetch latest AI/ML news articles.\"\"\"\n",
    "    agent = await agent_factory.get_initial_search_agent()\n",
    "    response = await agent.ainvoke(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": state.input_message}]},\n",
    "    )\n",
    "    return {\"news\": response[\"structured_response\"]}\n",
    "\n",
    "\n",
    "async def filter_news(state: NewsGraphState):\n",
    "    \"\"\"Filter news articles using a custom prompt.\"\"\"\n",
    "    assistant = await agent_factory.get_github_assistant(\n",
    "        specific_tool=[\"get_file_contents\", \"get_me\"],\n",
    "        response_format=NewsArticleList\n",
    "    )\n",
    "    prompt = prompt_loader.get_prompt(\"news_filter\")\n",
    "    rendered_prompt = await prompt.template.render_async(news=state.news.articles)\n",
    "    response = await assistant.ainvoke(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": rendered_prompt}]},\n",
    "    )\n",
    "    return {\"news\": response[\"structured_response\"]}\n",
    "\n",
    "\n",
    "async def map_to_articles(state: NewsGraphState):\n",
    "    \"\"\"Map each article to the summarization node using Send API.\"\"\"\n",
    "    return [Send(\"summarize_and_publish\", {\"article\": article}) for article in state.news.articles]\n",
    "\n",
    "# Modify summarize_and_publish to return the result for a single article\n",
    "\n",
    "\n",
    "async def summarize_and_publish(state: NewsGraphState):\n",
    "    \"\"\"Summarize and publish a single article.\"\"\"\n",
    "    supervisor = await agent_factory.get_supervisor()\n",
    "    prompt = prompt_loader.get_prompt(\"supervisor_agent_input\")\n",
    "    article = state[\"article\"] # This is the article from the Send API\n",
    "    rendered_prompt = await prompt.template.render_async(\n",
    "        title=article.title,\n",
    "        source=article.source,\n",
    "        date=article.date,\n",
    "        summary=article.summary,\n",
    "        url_ref=article.url\n",
    "    )\n",
    "    response = await supervisor.ainvoke(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": rendered_prompt}]},\n",
    "    )\n",
    "    # CORRECTED: Returns a list under the 'results' key for accumulation\n",
    "    return {\"results\": [response[\"messages\"][-1].content]}\n",
    "\n",
    "# Add a reduction node\n",
    "\n",
    "\n",
    "async def collect_results(state: NewsGraphState):\n",
    "    \"\"\"Collects results from all summarized articles.\"\"\"\n",
    "    # The 'results' field in NewsGraphState already handles accumulation\n",
    "    # due to Annotated[list, operator.add]. So this node might just be a pass-through\n",
    "    # or could perform additional aggregation if needed.\n",
    "    return {\"finished\": True} # The accumulator already has them\n",
    "\n",
    "\n",
    "def build_news_graph():\n",
    "    # reference: https://langchain-ai.github.io/langgraph/how-tos/graph-api/#map-reduce-and-the-send-api\n",
    "    builder = StateGraph(NewsGraphState)\n",
    "    builder.add_node(\"search_news\", search_news)\n",
    "    builder.add_node(\"filter_news\", filter_news)\n",
    "    builder.add_node(\"map_to_articles\", map_to_articles) # This node now acts as the dispatcher\n",
    "    builder.add_node(\"summarize_and_publish\", summarize_and_publish)\n",
    "    builder.add_node(\"collect_results\", collect_results)\n",
    "\n",
    "    builder.add_edge(START, \"search_news\")\n",
    "    builder.add_edge(\"search_news\", \"filter_news\")\n",
    "\n",
    "    # It returns a list of Send objects, and the targets are 'summarize_and_publish'\n",
    "    builder.add_conditional_edges(\n",
    "        \"filter_news\",          # The node from which to transition\n",
    "        map_to_articles,        # The function that decides the next step(s)\n",
    "        [\"summarize_and_publish\"] # The possible nodes that Send can target\n",
    "    )\n",
    "\n",
    "    builder.add_edge(\"summarize_and_publish\", \"collect_results\")\n",
    "    builder.add_edge(\"collect_results\", END)\n",
    "\n",
    "    return builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = build_news_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {\n",
    "    \"input_message\": \"Start searching for news about the latest trends in AI and machine learning. Provide maximum 2 articles.\" ,\n",
    "    \"news\": None,\n",
    "    \"article\": None,\n",
    "    \"results\": []\n",
    "}\n",
    "result = await graph.ainvoke(initial_state, config={\"callbacks\": [langfuse_handler], \"recursion_limit\": 200},)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The summary markdown file for the Meta Llama 4 release news has been created and committed on a new branch \"meta-llama4-release-summary\" in your \"ai-news-ignite\" GitHub repository under folder path news/2025-04/.  \\nA pull request to merge this new branch into main is now open for your review.  \\nLet me know if you need any further assistance!',\n",
       " 'The news article summary about DeepMind\\'s AlphaEvolve has been created and saved as a markdown file in the proper folder (news/2025-05/) within your \"ai-news-ignite\" GitHub repository. A new branch named \"add/deepmind-alphaevolve-news-2025-05\" was created, the changes committed and pushed, and a pull request has been opened to merge these updates into the \"main\" branch.\\n\\nIf you would like me to assist with anything else, please let me know!',\n",
       " 'The summary markdown file for the Meta Llama 4 release news has been created and committed on a new branch \"meta-llama4-release-summary\" in your \"ai-news-ignite\" GitHub repository under folder path news/2025-04/.  \\nA pull request to merge this new branch into main is now open for your review.  \\nLet me know if you need any further assistance!',\n",
       " 'The news article summary about DeepMind\\'s AlphaEvolve has been created and saved as a markdown file in the proper folder (news/2025-05/) within your \"ai-news-ignite\" GitHub repository. A new branch named \"add/deepmind-alphaevolve-news-2025-05\" was created, the changes committed and pushed, and a pull request has been opened to merge these updates into the \"main\" branch.\\n\\nIf you would like me to assist with anything else, please let me know!']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-news",
   "language": "python",
   "name": "ai-news"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
